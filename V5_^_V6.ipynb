{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EIHqpnDOgKZe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bea4887-9695-4330-fa5d-6e25c621856b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "V5 SHADOWMAP PHYSICS ENGINE: 144-D REGULARIZED CMA-ES (THE ORACLE CHASER)\n",
            "===========================================================================\n",
            "Fabricating d=9 chip with exactly 144 independent physical edges...\n",
            " -> Injecting 'Dead Quadrant' (20% error) in the Top-Right corner...\n",
            "Generating 80,000 CRN Training & Testing Trials...\n",
            "\n",
            "Evaluating Naive Baseline (Uniform weight = 3.178)...\n",
            " -> Baseline Train Rate: 0.02701\n",
            "\n",
            "Igniting L2-Regularized CMA-ES across 144 dimensions...\n",
            " -> CMA-ES GEN 01/60 | Best Train Fitness (Fails+L2): 2044.03\n",
            " -> CMA-ES GEN 05/60 | Best Train Fitness (Fails+L2): 1722.04\n",
            " -> CMA-ES GEN 10/60 | Best Train Fitness (Fails+L2): 1609.06\n",
            " -> CMA-ES GEN 15/60 | Best Train Fitness (Fails+L2): 1495.08\n",
            " -> CMA-ES GEN 20/60 | Best Train Fitness (Fails+L2): 1438.09\n",
            " -> CMA-ES GEN 25/60 | Best Train Fitness (Fails+L2): 1386.09\n",
            " -> CMA-ES GEN 30/60 | Best Train Fitness (Fails+L2): 1373.11\n",
            " -> CMA-ES GEN 35/60 | Best Train Fitness (Fails+L2): 1352.11\n",
            " -> CMA-ES GEN 40/60 | Best Train Fitness (Fails+L2): 1333.12\n",
            " -> CMA-ES GEN 45/60 | Best Train Fitness (Fails+L2): 1323.14\n",
            " -> CMA-ES GEN 50/60 | Best Train Fitness (Fails+L2): 1307.14\n",
            " -> CMA-ES GEN 55/60 | Best Train Fitness (Fails+L2): 1291.14\n",
            " -> CMA-ES GEN 60/60 | Best Train Fitness (Fails+L2): 1299.14\n",
            "\n",
            "===========================================================================\n",
            "V5 REGULARIZED OPTIMIZATION COMPLETE IN 860.97s\n",
            "===========================================================================\n",
            "TEST Baseline (Uniform):  0.02693 (2154/80000)\n",
            "TEST CMA-ES Optimized:    0.01725 (1380/80000)\n",
            "TEST Log-Odds ORACLE:     0.01574 (1259/80000)\n",
            "---------------------------------------------------------------------------\n",
            "McNemar (SHADOWMAP() vs Baseline):\n",
            "  AI saved: 1,223 | AI broke: 449 | p-value: 1.05e-79\n",
            "McNemar (AI vs ORACLE) - THE GAP:\n",
            "  Gap Size: 121 extra failures vs Oracle\n",
            "  Oracle saved, AI failed: 397 | AI saved, Oracle failed: 276\n",
            "  p-value: 3.73e-06\n",
            "===========================================================================\n",
            "\n",
            "SHADOWMAP() REGULARIZED ASCII RENDER:\n",
            "Phantom defects should be suppressed. The map should be surgically clean.\n",
            "\n",
            "HORIZONTAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-7):\n",
            "Row 0:   4.0    4.1    4.9    4.1    3.7  * 1.8* * 0.7* * 1.3*\n",
            "Row 1:   3.8    4.1    3.8    4.0    3.5    2.4    2.6  * 1.2*\n",
            "Row 2:   3.7    4.5    4.5    4.3    4.3  * 1.5* * 1.3* * 0.5*\n",
            "Row 3:   3.6    3.7    3.4    3.2    3.0  * 1.6* * 1.5* * 0.9*\n",
            "Row 4:   3.1    3.6    3.7    4.1    3.6    3.0  * 2.3* * 2.0*\n",
            "Row 5:   3.9    3.9    3.1    3.6    3.0    3.9    2.4  * 2.1*\n",
            "Row 6:   3.2    3.6    2.6    3.3    3.3    3.9  * 1.8*   3.6 \n",
            "Row 7:   4.0    3.3    2.8    3.4    3.2    2.8    2.7    2.6 \n",
            "Row 8:   4.3    3.2    2.6    3.4    3.6    2.4    2.9  * 2.1*\n",
            "\n",
            "VERTICAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-8):\n",
            "Row 0:   3.0    3.8    4.1    3.3    3.5  * 0.8*   3.1  * 2.1* * 1.9*\n",
            "Row 1:   2.5    4.4    3.7    3.0    3.6  * 1.0*   2.7    2.7    3.1 \n",
            "Row 2:   2.8    3.0    3.2    3.3    3.5  * 1.4* * 2.3*   2.3    3.8 \n",
            "Row 3:   2.4    3.4    3.3    3.5    4.1  * 2.3* * 0.8* * 2.1*   3.4 \n",
            "Row 4:   3.6    2.3    2.8    3.4    3.2    3.2    3.6    4.8    3.0 \n",
            "Row 5: * 0.5*   3.1    2.9    3.3  * 2.1*   3.8    2.6  * 2.1* * 0.8*\n",
            "Row 6: * 2.2*   3.8    3.7    3.3    3.4    3.2    3.2  * 2.3* * 1.4*\n",
            "Row 7:   3.1    4.0    3.8  * 2.0*   3.8    2.7    2.3  * 2.0* * 0.9*\n",
            "===========================================================================\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# V5 CELL 1 — THE SHADOWMAP ORACLE CHASER (144-D WITH L2 PRIOR & MEDIAN LOCK)\n",
        "# ==============================================================================\n",
        "\n",
        "import sys, subprocess, os, time, math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import scipy.stats\n",
        "import concurrent.futures\n",
        "\n",
        "try:\n",
        "    import cma\n",
        "    import pymatching\n",
        "except ImportError:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"cma\", \"pymatching\", \"scipy\"], check=True)\n",
        "    import cma\n",
        "    import pymatching\n",
        "\n",
        "print(\"=\"*75)\n",
        "print(\"V5 SHADOWMAP PHYSICS ENGINE: 144-D REGULARIZED CMA-ES (THE ORACLE CHASER)\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "d = 9\n",
        "p_good = 0.04\n",
        "p_bad = 0.20\n",
        "trials = 80000\n",
        "\n",
        "print(f\"Fabricating d={d} chip with exactly 144 independent physical edges...\")\n",
        "print(f\" -> Injecting 'Dead Quadrant' (20% error) in the Top-Right corner...\")\n",
        "\n",
        "H_rows, H_cols, L_cols, true_probs = [], [], [], []\n",
        "edge_types, edge_coords = [], []\n",
        "edge_idx = 0\n",
        "j_cut = d // 2\n",
        "\n",
        "for r in range(d):\n",
        "    for c in range(d):\n",
        "        u = r * d + c\n",
        "\n",
        "        # Horizontal\n",
        "        if c + 1 < d:\n",
        "            H_rows.extend([u, r * d + (c + 1)]); H_cols.extend([edge_idx, edge_idx])\n",
        "            is_defect = (r <= 3) and (c >= 5)\n",
        "            true_probs.append(p_bad if is_defect else p_good)\n",
        "            edge_types.append('H'); edge_coords.append((r, c))\n",
        "            if c == j_cut: L_cols.append(edge_idx)\n",
        "            edge_idx += 1\n",
        "\n",
        "        # Vertical\n",
        "        if r + 1 < d:\n",
        "            H_rows.extend([u, (r + 1) * d + c]); H_cols.extend([edge_idx, edge_idx])\n",
        "            is_defect = (r <= 3) and (c >= 5)\n",
        "            true_probs.append(p_bad if is_defect else p_good)\n",
        "            edge_types.append('V'); edge_coords.append((r, c))\n",
        "            edge_idx += 1\n",
        "\n",
        "num_physical_edges = edge_idx\n",
        "\n",
        "# Virtual Boundaries\n",
        "for r in range(d):\n",
        "    for c in (0, d - 1):\n",
        "        u = r * d + c\n",
        "        H_rows.append(u); H_cols.append(edge_idx)\n",
        "        true_probs.append(0.0)\n",
        "        edge_types.append('B'); edge_coords.append((r, c))\n",
        "        edge_idx += 1\n",
        "\n",
        "num_total_edges = edge_idx\n",
        "\n",
        "H = sp.csc_matrix(([1]*len(H_rows), (H_rows, H_cols)), shape=(d*d, num_total_edges), dtype=np.uint8)\n",
        "L = sp.csc_matrix(([1]*len(L_cols), ([0]*len(L_cols), L_cols)), shape=(1, num_total_edges), dtype=np.uint8)\n",
        "true_probs = np.array(true_probs)\n",
        "\n",
        "print(f\"Generating {trials:,} CRN Training & Testing Trials...\")\n",
        "H_csr, L_csr = H.tocsr(), L.tocsr()\n",
        "\n",
        "def make_crn(seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    noise = (rng.random((trials, num_total_edges)) < true_probs).astype(np.uint8)\n",
        "    syn = np.asarray((H_csr @ noise.T).T % 2, dtype=np.uint8)\n",
        "    obs = np.asarray((L_csr @ noise.T).T % 2, dtype=np.uint8)[:, 0]\n",
        "    return syn, obs\n",
        "\n",
        "syn_train, obs_train = make_crn(777)\n",
        "syn_test,  obs_test  = make_crn(888)\n",
        "\n",
        "initial_weight = math.log((1 - p_good) / p_good)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# THE PATCHES: Median Normalization & L2 Prior\n",
        "# ------------------------------------------------------------------------------\n",
        "def normalize_to_median(w, target_median):\n",
        "    w = np.maximum(0.01, np.asarray(w, dtype=np.float32))\n",
        "    med = np.median(w)\n",
        "    if med <= 0: return w\n",
        "    return w * (target_median / med)\n",
        "\n",
        "def evaluate_cma(weights_phys, dataset=\"train\", return_arr=False):\n",
        "    # PATCH 1: Fix Scale Degeneracy\n",
        "    weights_phys = normalize_to_median(weights_phys, initial_weight)\n",
        "\n",
        "    full_weights = np.zeros(num_total_edges, dtype=np.float32)\n",
        "    full_weights[:num_physical_edges] = weights_phys\n",
        "    full_weights[num_physical_edges:] = 0.0\n",
        "\n",
        "    matcher = pymatching.Matching.from_check_matrix(H, weights=full_weights, faults_matrix=L)\n",
        "\n",
        "    if dataset == \"train\":\n",
        "        pred = matcher.decode_batch(syn_train)[:, 0]\n",
        "        fails = int(np.sum(pred != obs_train))\n",
        "\n",
        "        # PATCH 2: L2 Regularization (Occam's Razor)\n",
        "        lambda_l2 = 1e-3\n",
        "        reg = lambda_l2 * float(np.sum((weights_phys - initial_weight)**2))\n",
        "        return fails + reg\n",
        "    else:\n",
        "        pred = matcher.decode_batch(syn_test)[:, 0]\n",
        "        arr = (pred != obs_test)\n",
        "        fails = int(np.sum(arr))\n",
        "        if return_arr:\n",
        "            return fails, arr\n",
        "        return fails\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(f\"\\nEvaluating Naive Baseline (Uniform weight = {initial_weight:.3f})...\")\n",
        "base_fails_train = evaluate_cma(np.ones(num_physical_edges) * initial_weight, \"train\")\n",
        "print(f\" -> Baseline Train Rate: {int(base_fails_train)/trials:.5f}\\n\")\n",
        "\n",
        "print(f\"Igniting L2-Regularized CMA-ES across 144 dimensions...\")\n",
        "t0 = time.time()\n",
        "\n",
        "# PATCH 3: CMA_diagonal & Popsize\n",
        "options = {\n",
        "    'bounds': [0.01, 10.0],\n",
        "    'popsize': 28,\n",
        "    'CMA_diagonal': 20,\n",
        "    'verbose': -9\n",
        "}\n",
        "es = cma.CMAEvolutionStrategy(np.ones(num_physical_edges) * initial_weight, 0.5, options)\n",
        "\n",
        "max_gens = 60\n",
        "\n",
        "# MATCH CORES TO POPSIZE MAX\n",
        "num_cores = min(os.cpu_count() or 1, 28)\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
        "    for gen in range(max_gens):\n",
        "        solutions = es.ask()\n",
        "        fitnesses = list(executor.map(lambda x: evaluate_cma(x, \"train\"), solutions))\n",
        "        es.tell(solutions, fitnesses)\n",
        "\n",
        "        best_fit = np.min(fitnesses)\n",
        "        if (gen+1) % 5 == 0 or gen == 0:\n",
        "            print(f\" -> CMA-ES GEN {gen+1:02d}/{max_gens} | Best Train Fitness (Fails+L2): {best_fit:.2f}\")\n",
        "\n",
        "opt_weights = normalize_to_median(es.result.xbest, initial_weight)\n",
        "elapsed = time.time() - t0\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# HOLDOUT TEST & ORACLE COMPARISON\n",
        "# ------------------------------------------------------------------------------\n",
        "opt_fails_test, opt_arr = evaluate_cma(opt_weights, \"test\", return_arr=True)\n",
        "base_fails_test, base_arr = evaluate_cma(np.ones(num_physical_edges) * initial_weight, \"test\", return_arr=True)\n",
        "\n",
        "th_weights = np.zeros(num_physical_edges)\n",
        "for i in range(num_physical_edges):\n",
        "    p = true_probs[i]\n",
        "    th_weights[i] = math.log((1 - p) / p) if p > 0 else 1.0\n",
        "\n",
        "th_fails_test, th_arr = evaluate_cma(th_weights, \"test\", return_arr=True)\n",
        "\n",
        "# McNemar: AI vs Baseline\n",
        "n01_base = int(np.sum((base_arr == True) & (opt_arr == False)))\n",
        "n10_base = int(np.sum((base_arr == False) & (opt_arr == True)))\n",
        "chi2_base = (abs(n01_base - n10_base) - 1)**2 / (n01_base + n10_base) if (n01_base + n10_base) > 0 else 0\n",
        "p_val_base = scipy.stats.chi2.sf(chi2_base, 1) if (n01_base + n10_base) > 0 else 1.0\n",
        "\n",
        "# PATCH 4: McNemar SHADOWMAP() vs ORACLE\n",
        "n01_ora = int(np.sum((th_arr == True) & (opt_arr == False)))\n",
        "n10_ora = int(np.sum((th_arr == False) & (opt_arr == True)))\n",
        "chi2_ora = (abs(n01_ora - n10_ora) - 1)**2 / (n01_ora + n10_ora) if (n01_ora + n10_ora) > 0 else 0\n",
        "p_val_ora = scipy.stats.chi2.sf(chi2_ora, 1) if (n01_ora + n10_ora) > 0 else 1.0\n",
        "\n",
        "print(\"\\n\" + \"=\"*75)\n",
        "print(f\"V5 REGULARIZED OPTIMIZATION COMPLETE IN {elapsed:.2f}s\")\n",
        "print(\"=\"*75)\n",
        "print(f\"TEST Baseline (Uniform):  {base_fails_test/trials:.5f} ({base_fails_test}/{trials})\")\n",
        "print(f\"TEST CMA-ES Optimized:    {opt_fails_test/trials:.5f} ({opt_fails_test}/{trials})\")\n",
        "print(f\"TEST Log-Odds ORACLE:     {th_fails_test/trials:.5f} ({th_fails_test}/{trials})\")\n",
        "print(\"-\" * 75)\n",
        "print(\"McNemar (SHADOWMAP() vs Baseline):\")\n",
        "print(f\"  AI saved: {n01_base:,} | AI broke: {n10_base:,} | p-value: {p_val_base:.2e}\")\n",
        "print(\"McNemar (AI vs ORACLE) - THE GAP:\")\n",
        "print(f\"  Gap Size: {opt_fails_test - th_fails_test} extra failures vs Oracle\")\n",
        "print(f\"  Oracle saved, AI failed: {n10_ora:,} | AI saved, Oracle failed: {n01_ora:,}\")\n",
        "print(f\"  p-value: {p_val_ora:.2e}\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "print(\"\\nSHADOWMAP() REGULARIZED ASCII RENDER:\")\n",
        "print(\"Phantom defects should be suppressed. The map should be surgically clean.\\n\")\n",
        "\n",
        "h_grid = np.zeros((d, d-1))\n",
        "v_grid = np.zeros((d-1, d))\n",
        "\n",
        "idx = 0\n",
        "for t, (r, c) in zip(edge_types[:num_physical_edges], edge_coords[:num_physical_edges]):\n",
        "    if t == 'H': h_grid[r, c] = opt_weights[idx]\n",
        "    elif t == 'V': v_grid[r, c] = opt_weights[idx]\n",
        "    idx += 1\n",
        "\n",
        "print(\"HORIZONTAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-7):\")\n",
        "for r in range(d):\n",
        "    row_str = \" \".join([f\"*{w:4.1f}*\" if w < 2.3 else f\" {w:4.1f} \" for w in h_grid[r]])\n",
        "    print(f\"Row {r}: {row_str}\")\n",
        "\n",
        "print(\"\\nVERTICAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-8):\")\n",
        "for r in range(d-1):\n",
        "    row_str = \" \".join([f\"*{w:4.1f}*\" if w < 2.3 else f\" {w:4.1f} \" for w in v_grid[r]])\n",
        "    print(f\"Row {r}: {row_str}\")\n",
        "print(\"=\"*75)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# V6 PHYSICS ENGINE: LLM-ENSEMBLE EDITION (THE ORACLE CHASER)\n",
        "# Architecture by Gemini | ML Regularization by ChatGPT 5.2 Pro\n",
        "# ==============================================================================\n",
        "\n",
        "import sys, subprocess, os, time, math\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import scipy.stats\n",
        "import concurrent.futures\n",
        "\n",
        "try:\n",
        "    import cma\n",
        "    import pymatching\n",
        "except ImportError:\n",
        "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"cma\", \"pymatching\", \"scipy\"], check=True)\n",
        "    import cma\n",
        "    import pymatching\n",
        "\n",
        "print(\"=\"*75)\n",
        "print(\"V6 PHYSICS ENGINE: 144-D LLM-ENSEMBLE REGULARIZED CMA-ES\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "d = 9\n",
        "p_good = 0.04\n",
        "p_bad = 0.20\n",
        "trials = 80000\n",
        "\n",
        "print(f\"Fabricating d={d} chip with 144 independent physical edges...\")\n",
        "print(f\" -> Injecting 'Dead Quadrant' (20% error) in Top-Right corner...\")\n",
        "\n",
        "H_rows, H_cols, L_cols, true_probs = [], [], [], []\n",
        "edge_types, edge_coords = [], []\n",
        "edge_idx = 0\n",
        "j_cut = d // 2\n",
        "\n",
        "for r in range(d):\n",
        "    for c in range(d):\n",
        "        u = r * d + c\n",
        "        if c + 1 < d:  # Horizontal\n",
        "            H_rows.extend([u, r * d + (c + 1)]); H_cols.extend([edge_idx, edge_idx])\n",
        "            is_defect = (r <= 3) and (c >= 5)\n",
        "            true_probs.append(p_bad if is_defect else p_good)\n",
        "            edge_types.append('H'); edge_coords.append((r, c))\n",
        "            if c == j_cut: L_cols.append(edge_idx)\n",
        "            edge_idx += 1\n",
        "        if r + 1 < d:  # Vertical\n",
        "            H_rows.extend([u, (r + 1) * d + c]); H_cols.extend([edge_idx, edge_idx])\n",
        "            is_defect = (r <= 3) and (c >= 5)\n",
        "            true_probs.append(p_bad if is_defect else p_good)\n",
        "            edge_types.append('V'); edge_coords.append((r, c))\n",
        "            edge_idx += 1\n",
        "\n",
        "num_physical_edges = edge_idx\n",
        "\n",
        "# Virtual Boundaries\n",
        "for r in range(d):\n",
        "    for c in (0, d - 1):\n",
        "        u = r * d + c\n",
        "        H_rows.append(u); H_cols.append(edge_idx)\n",
        "        true_probs.append(0.0)\n",
        "        edge_types.append('B'); edge_coords.append((r, c))\n",
        "        edge_idx += 1\n",
        "\n",
        "num_total_edges = edge_idx\n",
        "\n",
        "H = sp.csc_matrix(([1]*len(H_rows), (H_rows, H_cols)), shape=(d*d, num_total_edges), dtype=np.uint8)\n",
        "L = sp.csc_matrix(([1]*len(L_cols), ([0]*len(L_cols), L_cols)), shape=(1, num_total_edges), dtype=np.uint8)\n",
        "true_probs = np.array(true_probs)\n",
        "\n",
        "print(f\"Generating {trials:,} CRN Training & Testing Trials...\")\n",
        "H_csr, L_csr = H.tocsr(), L.tocsr()\n",
        "\n",
        "def make_crn(seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    noise = (rng.random((trials, num_total_edges)) < true_probs).astype(np.uint8)\n",
        "    syn = np.asarray((H_csr @ noise.T).T % 2, dtype=np.uint8)\n",
        "    obs = np.asarray((L_csr @ noise.T).T % 2, dtype=np.uint8)[:, 0]\n",
        "    return syn, obs\n",
        "\n",
        "syn_train, obs_train = make_crn(777)\n",
        "syn_test,  obs_test  = make_crn(888)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# CHATGPT PATCHES: Plausible Bounds, Post-Clip, Rate-Based L2\n",
        "# ------------------------------------------------------------------------------\n",
        "initial_weight = math.log((1 - p_good) / p_good)\n",
        "W_MIN = math.log((1 - 0.30) / 0.30)  # ~0.847\n",
        "W_MAX = math.log((1 - 0.01) / 0.01)  # ~4.595\n",
        "lambda_l2 = 3e-3\n",
        "\n",
        "def normalize_to_median(w, target_median):\n",
        "    w = np.maximum(0.01, np.asarray(w, dtype=np.float32))\n",
        "    med = np.median(w)\n",
        "    if med <= 0: return w\n",
        "    return w * (target_median / med)\n",
        "\n",
        "def evaluate_cma(weights_phys, dataset=\"train\", return_arr=False):\n",
        "    w = normalize_to_median(weights_phys, initial_weight)\n",
        "    w = np.clip(w, W_MIN, W_MAX) # ChatGPT Patch: Safe Bounds!\n",
        "\n",
        "    full_weights = np.zeros(num_total_edges, dtype=np.float32)\n",
        "    full_weights[:num_physical_edges] = w\n",
        "    full_weights[num_physical_edges:] = 0.0\n",
        "\n",
        "    matcher = pymatching.Matching.from_check_matrix(H, weights=full_weights, faults_matrix=L)\n",
        "\n",
        "    if dataset == \"train\":\n",
        "        pred = matcher.decode_batch(syn_train)[:, 0]\n",
        "        fails = int(np.sum(pred != obs_train))\n",
        "        fail_rate = fails / trials\n",
        "        # ChatGPT Patch: Regularize on RATE, not COUNT.\n",
        "        reg = lambda_l2 * float(np.mean((w - initial_weight)**2))\n",
        "        return float(fail_rate + reg)\n",
        "\n",
        "    pred = matcher.decode_batch(syn_test)[:, 0]\n",
        "    arr = (pred != obs_test)\n",
        "    fails = int(np.sum(arr))\n",
        "    if return_arr:\n",
        "        return fails, arr\n",
        "    return fails\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "print(f\"\\nEvaluating Naive Baseline (Uniform weight = {initial_weight:.3f})...\")\n",
        "base_fails_train = evaluate_cma(np.ones(num_physical_edges) * initial_weight, \"train\")\n",
        "print(f\" -> Baseline Train Rate (with L2): {base_fails_train:.5f}\\n\")\n",
        "\n",
        "print(f\"Igniting Rate-Regularized CMA-ES across 144 dimensions...\")\n",
        "t0 = time.time()\n",
        "\n",
        "options = {\n",
        "    'bounds': [W_MIN, W_MAX],\n",
        "    'popsize': 28,\n",
        "    'CMA_diagonal': 20,\n",
        "    'verbose': -9\n",
        "}\n",
        "# Adjusted initial sigma to 0.3 to match the tighter physical bounds\n",
        "es = cma.CMAEvolutionStrategy(np.ones(num_physical_edges) * initial_weight, 0.3, options)\n",
        "\n",
        "max_gens = 60\n",
        "num_cores = min(os.cpu_count() or 1, 28)\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=num_cores) as executor:\n",
        "    for gen in range(max_gens):\n",
        "        solutions = es.ask()\n",
        "        fitnesses = list(executor.map(lambda x: evaluate_cma(x, \"train\"), solutions))\n",
        "        es.tell(solutions, fitnesses)\n",
        "\n",
        "        best_fit = np.min(fitnesses)\n",
        "        if (gen+1) % 5 == 0 or gen == 0:\n",
        "            print(f\" -> CMA-ES GEN {gen+1:02d}/{max_gens} | Best Train Fitness (Rate+L2): {best_fit:.5f}\")\n",
        "\n",
        "opt_weights = normalize_to_median(es.result.xbest, initial_weight)\n",
        "opt_weights = np.clip(opt_weights, W_MIN, W_MAX)\n",
        "elapsed = time.time() - t0\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# HOLDOUT TEST & ORACLE COMPARISON\n",
        "# ------------------------------------------------------------------------------\n",
        "opt_fails_test, opt_arr = evaluate_cma(opt_weights, \"test\", return_arr=True)\n",
        "base_fails_test, base_arr = evaluate_cma(np.ones(num_physical_edges) * initial_weight, \"test\", return_arr=True)\n",
        "\n",
        "th_weights = np.zeros(num_physical_edges)\n",
        "for i in range(num_physical_edges):\n",
        "    p = true_probs[i]\n",
        "    th_weights[i] = math.log((1 - p) / p) if p > 0 else 1.0\n",
        "\n",
        "th_fails_test, th_arr = evaluate_cma(th_weights, \"test\", return_arr=True)\n",
        "\n",
        "n01_base = int(np.sum((base_arr == True) & (opt_arr == False)))\n",
        "n10_base = int(np.sum((base_arr == False) & (opt_arr == True)))\n",
        "p_val_base = scipy.stats.chi2.sf((abs(n01_base - n10_base) - 1)**2 / (n01_base + n10_base), 1) if (n01_base + n10_base) > 0 else 1.0\n",
        "\n",
        "n01_ora = int(np.sum((th_arr == True) & (opt_arr == False)))\n",
        "n10_ora = int(np.sum((th_arr == False) & (opt_arr == True)))\n",
        "p_val_ora = scipy.stats.chi2.sf((abs(n01_ora - n10_ora) - 1)**2 / (n01_ora + n10_ora), 1) if (n01_ora + n10_ora) > 0 else 1.0\n",
        "\n",
        "print(\"\\n\" + \"=\"*75)\n",
        "print(f\"V6 LLM-ENSEMBLE OPTIMIZATION COMPLETE IN {elapsed:.2f}s\")\n",
        "print(\"=\"*75)\n",
        "print(f\"TEST Baseline (Uniform):  {base_fails_test/trials:.5f} ({base_fails_test}/{trials})\")\n",
        "print(f\"TEST CMA-ES Optimized:    {opt_fails_test/trials:.5f} ({opt_fails_test}/{trials})\")\n",
        "print(f\"TEST Log-Odds ORACLE:     {th_fails_test/trials:.5f} ({th_fails_test}/{trials})\")\n",
        "print(\"-\" * 75)\n",
        "print(\"McNemar (AI vs ORACLE) - THE GAP:\")\n",
        "print(f\"  Gap Size: {opt_fails_test - th_fails_test} extra failures vs Oracle\")\n",
        "print(f\"  Oracle saved, AI failed: {n10_ora:,} | AI saved, Oracle failed: {n01_ora:,}\")\n",
        "print(f\"  p-value: {p_val_ora:.2e}\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# MAP QUALITY DIAGNOSTICS (AUC)\n",
        "# ------------------------------------------------------------------------------\n",
        "is_defect = np.array([(r <= 3) and (c >= 5) for t, (r, c) in zip(edge_types[:num_physical_edges], edge_coords[:num_physical_edges])], dtype=bool)\n",
        "\n",
        "w_def = opt_weights[is_defect]\n",
        "w_ok  = opt_weights[~is_defect]\n",
        "\n",
        "scores = -opt_weights\n",
        "labels = is_defect.astype(int)\n",
        "order = np.argsort(scores)\n",
        "ranks = np.empty_like(order)\n",
        "ranks[order] = np.arange(len(scores)) + 1\n",
        "n_pos = labels.sum()\n",
        "n_neg = len(labels) - n_pos\n",
        "auc = (ranks[labels == 1].sum() - n_pos*(n_pos+1)/2) / (n_pos*n_neg) if n_pos*n_neg>0 else float('nan')\n",
        "\n",
        "print(\"DEFECT DETECTION AUDIT (AUC & SEPARATION)\")\n",
        "print(f\"   Mean Weight   -> Defect Zone: {float(w_def.mean()):.4f} | Healthy Zone: {float(w_ok.mean()):.4f}\")\n",
        "print(f\"   AUC Score     -> {float(auc):.4f} (1.0 is perfect separation)\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "print(\"\\nSHADOWMAP() V6 ASCII RENDER:\")\n",
        "h_grid, v_grid = np.zeros((d, d-1)), np.zeros((d-1, d))\n",
        "idx = 0\n",
        "for t, (r, c) in zip(edge_types[:num_physical_edges], edge_coords[:num_physical_edges]):\n",
        "    if t == 'H': h_grid[r, c] = opt_weights[idx]\n",
        "    elif t == 'V': v_grid[r, c] = opt_weights[idx]\n",
        "    idx += 1\n",
        "\n",
        "print(\"HORIZONTAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-7):\")\n",
        "for r in range(d):\n",
        "    row_str = \" \".join([f\"*{w:4.1f}*\" if w < 2.3 else f\" {w:4.1f} \" for w in h_grid[r]])\n",
        "    print(f\"Row {r}: {row_str}\")\n",
        "\n",
        "print(\"\\nVERTICAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-8):\")\n",
        "for r in range(d-1):\n",
        "    row_str = \" \".join([f\"*{w:4.1f}*\" if w < 2.3 else f\" {w:4.1f} \" for w in v_grid[r]])\n",
        "    print(f\"Row {r}: {row_str}\")\n",
        "print(\"=\"*75)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pcuhtn9qb0M",
        "outputId": "4f72d0c1-bef4-4b0a-f50b-39969e599c8a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "V6 PHYSICS ENGINE: 144-D LLM-ENSEMBLE REGULARIZED CMA-ES\n",
            "===========================================================================\n",
            "Fabricating d=9 chip with 144 independent physical edges...\n",
            " -> Injecting 'Dead Quadrant' (20% error) in Top-Right corner...\n",
            "Generating 80,000 CRN Training & Testing Trials...\n",
            "\n",
            "Evaluating Naive Baseline (Uniform weight = 3.178)...\n",
            " -> Baseline Train Rate (with L2): 0.02701\n",
            "\n",
            "Igniting Rate-Regularized CMA-ES across 144 dimensions...\n",
            " -> CMA-ES GEN 01/60 | Best Train Fitness (Rate+L2): 0.02503\n",
            " -> CMA-ES GEN 05/60 | Best Train Fitness (Rate+L2): 0.02246\n",
            " -> CMA-ES GEN 10/60 | Best Train Fitness (Rate+L2): 0.02055\n",
            " -> CMA-ES GEN 15/60 | Best Train Fitness (Rate+L2): 0.01945\n",
            " -> CMA-ES GEN 20/60 | Best Train Fitness (Rate+L2): 0.01872\n",
            " -> CMA-ES GEN 25/60 | Best Train Fitness (Rate+L2): 0.01811\n",
            " -> CMA-ES GEN 30/60 | Best Train Fitness (Rate+L2): 0.01770\n",
            " -> CMA-ES GEN 35/60 | Best Train Fitness (Rate+L2): 0.01783\n",
            " -> CMA-ES GEN 40/60 | Best Train Fitness (Rate+L2): 0.01790\n",
            " -> CMA-ES GEN 45/60 | Best Train Fitness (Rate+L2): 0.01777\n",
            " -> CMA-ES GEN 50/60 | Best Train Fitness (Rate+L2): 0.01720\n",
            " -> CMA-ES GEN 55/60 | Best Train Fitness (Rate+L2): 0.01747\n",
            " -> CMA-ES GEN 60/60 | Best Train Fitness (Rate+L2): 0.01710\n",
            "\n",
            "===========================================================================\n",
            "V6 LLM-ENSEMBLE OPTIMIZATION COMPLETE IN 852.08s\n",
            "===========================================================================\n",
            "TEST Baseline (Uniform):  0.02693 (2154/80000)\n",
            "TEST CMA-ES Optimized:    0.01704 (1363/80000)\n",
            "TEST Log-Odds ORACLE:     0.01574 (1259/80000)\n",
            "---------------------------------------------------------------------------\n",
            "McNemar (AI vs ORACLE) - THE GAP:\n",
            "  Gap Size: 104 extra failures vs Oracle\n",
            "  Oracle saved, AI failed: 380 | AI saved, Oracle failed: 276\n",
            "  p-value: 5.78e-05\n",
            "===========================================================================\n",
            "DEFECT DETECTION AUDIT (AUC & SEPARATION)\n",
            "   Mean Weight   -> Defect Zone: 2.1185 | Healthy Zone: 3.2659\n",
            "   AUC Score     -> 0.9116 (1.0 is perfect separation)\n",
            "===========================================================================\n",
            "\n",
            "SHADOWMAP() V6 ASCII RENDER:\n",
            "HORIZONTAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-7):\n",
            "Row 0:   3.8    3.8    3.9    3.5    3.6  * 1.9* * 1.8* * 1.6*\n",
            "Row 1:   3.8    3.3    3.8    3.2    3.2  * 1.6* * 2.2* * 2.1*\n",
            "Row 2:   3.7    3.7    3.5    3.4    4.2  * 1.9* * 2.0* * 1.0*\n",
            "Row 3:   3.9    2.9    3.8    3.5    3.5  * 0.9* * 1.0* * 1.0*\n",
            "Row 4:   2.9    3.7    3.6    3.7    3.7    3.3    2.6    2.7 \n",
            "Row 5:   3.5    3.5    3.2    3.2    3.2    3.2    3.2    2.8 \n",
            "Row 6:   3.4    3.4    3.1    3.4    3.0    3.2    3.1    3.1 \n",
            "Row 7:   3.0    3.2    3.3    3.3    3.2    3.0    3.4    3.1 \n",
            "Row 8:   3.3    2.5    3.7    3.6    4.4    3.8    3.1    3.4 \n",
            "\n",
            "VERTICAL EDGE WEIGHTS (Expected Defect: Rows 0-3, Cols 5-8):\n",
            "Row 0:   3.9    2.7    3.7    3.3    3.3  * 1.9*   3.0    3.6    3.3 \n",
            "Row 1:   3.0    3.4    4.0    2.6    3.1  * 1.9*   3.0    2.5    2.6 \n",
            "Row 2:   3.6    3.4    3.1    3.5    3.5  * 1.3* * 1.9*   2.7    2.7 \n",
            "Row 3: * 2.3*   3.3    2.5    2.9    3.3  * 1.7*   2.7    2.6    3.0 \n",
            "Row 4:   2.9    2.7    2.7    3.6    3.0    3.5    3.6    4.1    2.9 \n",
            "Row 5:   3.4    3.7    3.2  * 2.2*   2.6    3.2    2.7    2.8    3.4 \n",
            "Row 6:   2.9    3.3  * 2.2*   3.5    2.8    3.0    2.9    3.1    2.8 \n",
            "Row 7:   2.8  * 2.3* * 2.1*   3.6    4.1    3.7    3.1    3.1    4.0 \n",
            "===========================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, math\n",
        "import pymatching\n",
        "\n",
        "# log-odds weight for the healthy region\n",
        "w_good = math.log((1-p_good)/p_good)\n",
        "\n",
        "def normalize_to_median(w, target):\n",
        "    w = np.maximum(0.01, np.asarray(w, dtype=np.float32))\n",
        "    med = float(np.median(w))\n",
        "    return w if med <= 0 else w * (target / med)\n",
        "\n",
        "def eval_phys_weights(phys_w, syn, obs):\n",
        "    full = np.zeros(num_total_edges, dtype=np.float32)\n",
        "    full[:num_physical_edges] = phys_w\n",
        "    full[num_physical_edges:] = 0.0\n",
        "    m = pymatching.Matching.from_check_matrix(H, weights=full, faults_matrix=L)\n",
        "    pred = m.decode_batch(syn)[:,0]\n",
        "    arr = (pred != obs)\n",
        "    return int(arr.sum()), arr\n",
        "\n",
        "# Start from your learned weights, scale-lock to w_good\n",
        "w = normalize_to_median(opt_weights, w_good)\n",
        "\n",
        "# Use a subsample for fast model selection\n",
        "subN = 10000\n",
        "syn_sub = syn_train[:subN]\n",
        "obs_sub = obs_train[:subN]\n",
        "\n",
        "# Candidate thresholds: choose by quantiles of learned weights\n",
        "qs = np.linspace(0.05, 0.30, 14)  # defect fraction candidates\n",
        "thr_vals = np.quantile(w, qs)\n",
        "\n",
        "# Candidate defect weights: search a plausible range (centered around the true regime)\n",
        "# If you know p_bad ~0.2, w_bad~1.386, but we keep it generic.\n",
        "w_bad_grid = np.linspace(0.85, 2.4, 16)\n",
        "\n",
        "best = None\n",
        "for thr in thr_vals:\n",
        "    mask = (w < thr)\n",
        "    for w_bad in w_bad_grid:\n",
        "        w_snap = np.where(mask, w_bad, w_good).astype(np.float32)\n",
        "        k_sub, _ = eval_phys_weights(w_snap, syn_sub, obs_sub)\n",
        "        rate_sub = k_sub / subN\n",
        "        if best is None or rate_sub < best[0]:\n",
        "            best = (rate_sub, float(thr), float(w_bad), int(mask.sum()))\n",
        "\n",
        "print(\"Best snap on subsample:\")\n",
        "print(\"  rate_sub =\", best[0], \"thr =\", best[1], \"w_bad =\", best[2], \"defect_edges =\", best[3])\n",
        "\n",
        "# Evaluate best snap on full train + test\n",
        "_, thr, w_bad, _ = best\n",
        "mask = (w < thr)\n",
        "w_snap = np.where(mask, w_bad, w_good).astype(np.float32)\n",
        "\n",
        "k_train, train_arr = eval_phys_weights(w_snap, syn_train, obs_train)\n",
        "k_test,  test_arr  = eval_phys_weights(w_snap, syn_test,  obs_test)\n",
        "\n",
        "print(\"\\nSNAP RESULTS (two-level weights):\")\n",
        "print(f\"  Train rate: {k_train/len(obs_train):.5f} ({k_train}/{len(obs_train)})\")\n",
        "print(f\"  Test  rate: {k_test/len(obs_test):.5f} ({k_test}/{len(obs_test)})\")\n",
        "print(f\"  Learned w_bad: {w_bad:.3f}  (w_good: {w_good:.3f})\")\n",
        "print(f\"  Flagged defect edges: {mask.sum()} / {num_physical_edges}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noRVN9NtqcwS",
        "outputId": "ab77d5c0-5baa-4908-ab6f-6033670766ba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best snap on subsample:\n",
            "  rate_sub = 0.0152 thr = 2.2339259028434753 w_bad = 0.85 defect_edges = 19\n",
            "\n",
            "SNAP RESULTS (two-level weights):\n",
            "  Train rate: 0.01649 (1319/80000)\n",
            "  Test  rate: 0.01692 (1354/80000)\n",
            "  Learned w_bad: 0.850  (w_good: 3.178)\n",
            "  Flagged defect edges: 19 / 144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# V6.1 CELL — THE CLASSIFIER SNAP (Bridging the Final Oracle Gap)\n",
        "# Architecture by ChatGPT 5.2 Pro\n",
        "# ==============================================================================\n",
        "import numpy as np\n",
        "import math\n",
        "import scipy.stats\n",
        "import pymatching\n",
        "\n",
        "print(\"=\"*75)\n",
        "print(\"V6.1: SNAP-TO-TWO-LEVEL POST-PROCESSING\")\n",
        "print(\"=\"*75)\n",
        "\n",
        "# log-odds weight for the healthy region\n",
        "w_good = math.log((1 - p_good) / p_good)\n",
        "\n",
        "def normalize_to_median(w, target):\n",
        "    w = np.maximum(0.01, np.asarray(w, dtype=np.float32))\n",
        "    med = float(np.median(w))\n",
        "    return w if med <= 0 else w * (target / med)\n",
        "\n",
        "def eval_phys_weights(phys_w, syn, obs, return_arr=False):\n",
        "    full = np.zeros(num_total_edges, dtype=np.float32)\n",
        "    full[:num_physical_edges] = phys_w\n",
        "    full[num_physical_edges:] = 0.0\n",
        "    m = pymatching.Matching.from_check_matrix(H, weights=full, faults_matrix=L)\n",
        "    pred = m.decode_batch(syn)[:,0]\n",
        "    arr = (pred != obs)\n",
        "    if return_arr:\n",
        "        return int(arr.sum()), arr\n",
        "    return int(arr.sum())\n",
        "\n",
        "# Start from your learned weights, scale-lock to w_good\n",
        "w = normalize_to_median(opt_weights, w_good)\n",
        "\n",
        "# Use a subsample for fast model selection (10,000 trials)\n",
        "subN = 10000\n",
        "syn_sub = syn_train[:subN]\n",
        "obs_sub = obs_train[:subN]\n",
        "\n",
        "print(\"Executing 2D Grid Search on Subsample (Threshold vs w_bad)...\")\n",
        "\n",
        "# Candidate thresholds: choose by quantiles of learned weights\n",
        "qs = np.linspace(0.05, 0.30, 14)\n",
        "thr_vals = np.quantile(w, qs)\n",
        "\n",
        "# Candidate defect weights: search a plausible range\n",
        "w_bad_grid = np.linspace(0.85, 2.4, 16)\n",
        "\n",
        "best = None\n",
        "for thr in thr_vals:\n",
        "    mask = (w < thr)\n",
        "    for w_bad in w_bad_grid:\n",
        "        w_snap = np.where(mask, w_bad, w_good).astype(np.float32)\n",
        "        k_sub = eval_phys_weights(w_snap, syn_sub, obs_sub)\n",
        "        rate_sub = k_sub / subN\n",
        "        if best is None or rate_sub < best[0]:\n",
        "            best = (rate_sub, float(thr), float(w_bad), int(mask.sum()))\n",
        "\n",
        "print(f\" -> Best Subsample Rate: {best[0]:.5f}\")\n",
        "print(f\" -> Optimal Threshold:   w < {best[1]:.3f}\")\n",
        "print(f\" -> Optimal w_bad:       {best[2]:.3f}\")\n",
        "print(f\" -> Atoms Flagged Dead:  {best[3]} / {num_physical_edges}\\n\")\n",
        "\n",
        "# Evaluate best snap on full train + test\n",
        "_, thr, w_bad, flagged_count = best\n",
        "mask = (w < thr)\n",
        "w_snap = np.where(mask, w_bad, w_good).astype(np.float32)\n",
        "\n",
        "print(f\"Deploying Snapped Weights to full {trials:,} Testing set...\")\n",
        "k_train = eval_phys_weights(w_snap, syn_train, obs_train)\n",
        "k_test, test_arr_snap = eval_phys_weights(w_snap, syn_test, obs_test, return_arr=True)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# THE FINAL MCNEMAR VS ORACLE\n",
        "# ------------------------------------------------------------------------------\n",
        "# We still have th_arr and th_fails_test in memory from V6!\n",
        "n01_ora = int(np.sum((th_arr == True) & (test_arr_snap == False)))\n",
        "n10_ora = int(np.sum((th_arr == False) & (test_arr_snap == True)))\n",
        "chi2_ora = (abs(n01_ora - n10_ora) - 1)**2 / (n01_ora + n10_ora) if (n01_ora + n10_ora) > 0 else 0\n",
        "p_val_ora = scipy.stats.chi2.sf(chi2_ora, 1) if (n01_ora + n10_ora) > 0 else 1.0\n",
        "\n",
        "print(\"\\n\" + \"=\"*75)\n",
        "print(\"SNAP RESULTS (TWO-LEVEL WEIGHTS):\")\n",
        "print(\"=\"*75)\n",
        "print(f\"  Train rate:            {k_train/trials:.5f} ({k_train}/{trials})\")\n",
        "print(f\"  Test rate (SNAPPED):   {k_test/trials:.5f} ({k_test}/{trials})\")\n",
        "print(f\"  Test rate (ORACLE):    {th_fails_test/trials:.5f} ({th_fails_test}/{trials})\")\n",
        "print(\"-\" * 75)\n",
        "print(f\"  Learned w_bad:         {w_bad:.3f} (Theoretical Truth: 1.386)\")\n",
        "print(f\"  Learned w_good:        {w_good:.3f} (Theoretical Truth: 3.178)\")\n",
        "print(f\"  Flagged defect edges:  {flagged_count} / {num_physical_edges} (True defect count is 36)\")\n",
        "print(\"-\" * 75)\n",
        "print(\"FINAL MCNEMAR (SNAPPED AI vs ORACLE) - THE GAP:\")\n",
        "print(f\"  Gap Size: {k_test - th_fails_test} extra failures vs Oracle\")\n",
        "print(f\"  Oracle saved, AI failed: {n10_ora:,} | AI saved, Oracle failed: {n01_ora:,}\")\n",
        "print(f\"  p-value: {p_val_ora:.2e}\")\n",
        "print(\"=\"*75)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZPRAZfq2BYz",
        "outputId": "fa3604ac-39a2-440c-df30-72bace1a9004"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========================================================================\n",
            "V6.1: SNAP-TO-TWO-LEVEL POST-PROCESSING\n",
            "===========================================================================\n",
            "Executing 2D Grid Search on Subsample (Threshold vs w_bad)...\n",
            " -> Best Subsample Rate: 0.01520\n",
            " -> Optimal Threshold:   w < 2.234\n",
            " -> Optimal w_bad:       0.850\n",
            " -> Atoms Flagged Dead:  19 / 144\n",
            "\n",
            "Deploying Snapped Weights to full 80,000 Testing set...\n",
            "\n",
            "===========================================================================\n",
            "SNAP RESULTS (TWO-LEVEL WEIGHTS):\n",
            "===========================================================================\n",
            "  Train rate:            0.01649 (1319/80000)\n",
            "  Test rate (SNAPPED):   0.01692 (1354/80000)\n",
            "  Test rate (ORACLE):    0.01574 (1259/80000)\n",
            "---------------------------------------------------------------------------\n",
            "  Learned w_bad:         0.850 (Theoretical Truth: 1.386)\n",
            "  Learned w_good:        3.178 (Theoretical Truth: 3.178)\n",
            "  Flagged defect edges:  19 / 144 (True defect count is 36)\n",
            "---------------------------------------------------------------------------\n",
            "FINAL MCNEMAR (SNAPPED AI vs ORACLE) - THE GAP:\n",
            "  Gap Size: 95 extra failures vs Oracle\n",
            "  Oracle saved, AI failed: 291 | AI saved, Oracle failed: 196\n",
            "  p-value: 2.05e-05\n",
            "===========================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6kU3xOwl3cCv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}